---
title: Bayesian inference using Markov chain Monte Carlo
subtitle: "Part 1: Foundations and Implementation"
layout: lecture
---

<section>
  <section class="center">
    <h1>Introduction</h1>
  </section>
  
  <section>
    <h2>Bayesian inference</h2>

    <ul>
      <li>Bayesian inference is enabled by the Bayesian interpretation of probabilities:
        <ul>
          <li>Probabilities are just as applicable to hypotheses as they are to data.</li>
          <li>Inference of models and/or model parameters can be conducted using the standard calculus of probabilities (sum rule, product rule, etc).</li>
      </ul></li>
      <li>In contrast, sampling theory approaches assign probabilities only to data:
        <ul>
          <li>Inference of models and/or parameters is a distinct procedure.
        </ul>
      </li>
  </section>

  <section>
    <h2>The Problem</h2>

    <p>Suppose we have a vector $\vec{d}$ representing some collected data.  Assuming a model $M$, what do the data tell us about the parameters $\vec{\theta}_M$ of this model?</p>

    <p>The Bayesian solution is simple to derive and tremendously intuitive:</p>

    $$P(\vec{\theta}_M|\vec{d},M) = \frac{P(\vec{d}|\vec{\theta}_M,M)P(\vec{\theta}_M)}{P(\vec{d}|M)}$$

    <p>For models with large parameter space volumes,
    actually <i>evaluating</i> this probability for a particular
    $\vec{\theta}_M$ is HARD.</p>

    $$P(\vec{d}|M)=\sum_{\vec{\theta}_M} P(\vec{d}|\vec{\theta}_M,M)P(\vec{\theta}_M|M)$$
  </section>

  <section>
    <h2>The Problem (Continued)</h2>

    <div class="figure">
    <img data-src="ship_lake.svg" style="width:80%">
    <div class="cite" style="text-align:right">Idea due to MacKay, 2003</div>
    </div>
  </section>

  <section>
    <h2>A practical example from phylogenetics</h2>

    <p>The posterior probability for a particular time tree $T$ given a multiple sequence alignment $A$ and a neutral substitution model and a coalescent prior on tree space is</p>
    $$P(T,\mu,\theta|A) = \frac{P(A|T,\mu)P(T|\theta)P(\mu,\theta)}{P(A)}$$
    <p>where $\mu$ and $\theta$ are substitution model and tree prior parameters.</p>

    <p>How difficult is it to compute the denominator?</p>
    $$P(A)=\sum_{T,\mu,\theta}P(A|T,\mu)P(T|\theta)P(\mu,\theta)$$
  </section>

  <section>
    <h2>How big is tree space?</h2>

    <p>The number $N$ of distinct labelled rooted tree topologies
      grows rapidly with the number $m$ of leaves
      (i.e. sequences in our problem):</p>

    $$N_m = \frac{(2m-3)!}{2^{m-2}(m-2)!}$$

    <div id="treecount" class="figure">
      <script src="plot_treecount.js"></script>
    </div>
  </section>

  <section>
    <h2>Computational solutions to the normalization problem</h2>

    <ol class="spaced">
      <li>Use <b>brute-force enumeration</b> all possible states:
        $$\sum_{\vec{\theta}_M}P(\vec{d}|\vec{\theta}_M,M)P(\vec{\theta}_M|M)$$
        <ul><li>Only computationally feasible for relatively small problems.</li></ul>
      </li>
      <li>Use a <b>variational approach</b> (AKA "variational Bayes"):<br>
        find $Q(\vec{\theta}_M)$ minimizing $\sum_{\vec{\theta}_M}Q(\vec{\theta}_M)\log\frac{Q(\vec{\theta}_M)}{P(\vec{\theta}_M|\vec{d},M)}$.
        <ul><li>Requires a parametric ansatz for the posterior.  Not always easy to find, particularly in "interesting" state spaces such as tree space.</li></ul>
        </li>
    </ol>

  </section>

</section>

<section>
  <section class="center">
    <h1>The MCMC Algorithm</h1>
  </section>

  <section>
    <h2>Monte Carlo Methods</h2>

    <ul>
      <li>Broad class of methods which use stochastic algorithms to mathematical problems.</li>
      <li>A large sub-class of these methods are targeted at the numerical solution of analytically intractable integrals:
        \begin{align}
        I &= \int_{\vec{x}\in\mathcal{V}} f(\vec{x})p(\vec{x})\\
          &= E_p[f(\vec{x})]
        \end{align}</li>
      <li>By the law of large numbers:
        $$I = \lim_{N\rightarrow\infty} \frac{1}{N}\sum_{i=1}^N f(\vec{x}^{(i)})$$
        where $\vec{x}^{(i)}$ are draws from the distribution $p(\vec{x})$.</li>
    </ul>
  </section>

  <section>
    <h2>Monte Carlo Methods (Continued)</h2>

    <div class="figure" style="display:inline-block;width:50%">
      <img data-src="Pi_30K_slow.gif" style="width:100%">
      <div class="cite" style="text-align:right">Wikipedia</div>
    </div>
    <p>Here $\mathcal{V}=[0,1]^2$, $p(\vec{x})=1$ and $f(\vec{x})=I(|\vec{x}|^2<1)$.</p>
  </section>

  <section>
    <h2>Importance Sampling</h2>

    <ul>
      <li>What happens if we can't sample directly from $p(\vec{x})$?</li>
      <li>Solution: suppose we have a function $Q(\vec{x})$ also defined on $\mathcal{V}$ from which we can easily generate samples:
        <div class="figure" style="text-align:center">
          <img data-src="importance_sampling.svg" style="width:40%">
      </div></li>
      <li>We can then use
        $$I=\int_{\vec{x}\in\mathcal{V}}f(\vec{x})\frac{p(\vec{x})}{q(\vec{x})}q(\vec{x}) = E_q\left[f(\vec{x})\frac{p(\vec{x})}{q(\vec{x})}\right]$$</li>

      <li style="margin-top:1.0em">The factor $p(\vec{x}^{(i)})/q(\vec{x}^{(i)})$ is the <b>weight</b> of sample $\vec{x}^{(i)}$.
    </ul>
  </section>

  <section>
    <h2>Importance Sampling in a Bayesian context</h2>

    <ul>
      <li>Importance sampling is a very general and useful idea with many applications in Bayesian statistics.</li>
      <li>A very na&iuml;ve application would be the computation of the normalization factor in Bayes theorem:
        $$P(\vec{d}|M)=\lim_{N\rightarrow\infty}\frac{1}{N}\sum_{i=1}^{N}P(\vec{d}|\vec{\theta}_M^{(i)})$$
        where $\vec{\theta}_M^{(i)}\sim P(\vec{\theta}_M|M)$.</li>
      <li>Similarly, one could compute expectations of parameters under the posterior.</li>
      <li>Note that the equation above still holds if unbiased noise is added to the likelihood.</li>
    </ul>
  </section>

  <section>
    <h2>Approximate Bayesian Computation</h2>

    <ul>
      <li>Suppose we can't even evaluate the likelihood $P(\vec{d}|\vec{\theta}_M,M)$. What then?</li>
      <li>An example from population genetics might be the probability of a sequence alignment $A$ given some population parameters $\phi=(N(t), \rho, \ldots)$. This probability $P(A|\phi)$ is difficult to compute as it requires summing over a large number of latent variables (including the sampled phylogenetic tree/network).</li>
      <li>ABC: Replace the likelihood with a <b>cost function</b> depending
      on the difference between summary statistics evaluated on data
      $\vec{d}_s$ simulated under the $M$ from parameters
      $\vec{\theta}_M$ and the same summaries evaluate using the observed
      data $\vec{d}$.</li>

      <li>While this method seems less than rigorous, there are systematic ways of applying it.</li>
      </ul>
  </section>
  
  <section>
    <h2>Markov chain Monte Carlo methods</h2>

    <ul>
      <li>Until now we have assumed each sample $\vec{x}^{(i)}$ is statistically independent.</li>
      <li>Markov chain Monte Carlo methods instead produce a sequence
        of correlated samples
        $\vec{x}^{(1)}, \vec{x}^{(2)},\ldots,\vec{x}^{(N)}$,
        where each element is drawn from a distribution depending only
      on the previous element:
        $$\vec{x}^{(i+1)} \sim Q(\vec{x}'|\vec{x}^{(i)})$$</li>
      <li>Allows samples to adapt to shape of distribution:
        <div class="figure" style="text-align:center">
          <img data-src="markov_chain.svg" style="width:50%">
        </div>
      </li>
    </ul>
  </section>

  <section>
    <h2>The Gibbs sampler</h2>

    <ul>
      <li>To be useful, the Markov chain must be ergodic in the following sense:
        $$\lim_{N\rightarrow\infty}\frac{1}{N}\sum_{i=1}^{N}f(\vec{x}^{(i)})=\int_{\vec{x}\in\mathcal{V}} f(\vec{x})p(\vec{x})$$</li>
      <li>That is, the stationary distribution of the chain must match $p(\vec{x})$. Thus, the transition probabilities must be chosen so that they do not perturb the stationary distribution.</li>
      <li>One way to achieve this is to use a sequence of transition functions which sample individual elements of the state vector from the conditional distributions $p(x_k|\vec{x}_{-k})$.</li>
      <li>This is possible only when these conditional probabilities are known.</li>
    </ul>
  </section>

  <section>
    <h2>Metropolis-Hastings sampling</h2>

    <ul>
      <li>Suppose instead that we have the following transition probability:
        $$Q(\vec{x}'|\vec{x})=\alpha(\vec{x}',\vec{x})q(\vec{x}'|\vec{x}) + \delta(\vec{x}'-\vec{x})(1-\int_{\vec{y}\in\mathcal{V}}\alpha(\vec{y},\vec{x})q(\vec{y}|\vec{x}))$$
      </li>
      <li>Here $q(\vec{x}'|\vec{x})$ is an arbitrary transition probability distribution (as long as ergodicity is satisfiable) and $\alpha(\vec{x}',\vec{x})$ is the <i>acceptance probability</i>.</li>
      <li>Assuming that the stationary distribution of the chain satisfies detailed balance allows us to write
        $$p(\vec{x})Q(\vec{x}'|\vec{x}) = p(\vec{x}')Q(\vec{x}|\vec{x}')$$</li>
    </ul>
  </section>

  <section>
    <h2>Metropolis-Hastings sampling (continued)</h2>
    <ul>
      <li>From this it is straight-forward to identify the following solution for $\alpha$:

        $$\alpha(\vec{x}',\vec{x})=1\wedge\frac{p(\vec{x}')}{p(\vec{x})}\cdot\frac{q(\vec{x}|\vec{x}')}{q(\vec{x}'|\vec{x})}$$
      </li>
      <li>The ratio $q(\vec{x}|\vec{x}')/q(\vec{x}'|\vec{x})$ is known
        as the Hastings ratio, and accounts for asymmetry in the
        proposal distribution.</li>
      <li>This isn't the only possibility for $\alpha$:
        <ul>
          <li>It's possible to find Markov chains with the
          transition probability given that have $p(\vec{x})$ as a
          stationary distribution but which violate detailed
          balance.</li>
          <li>It's also possible to find $\alpha$ such that both
          $\alpha(\vec{x}',\vec{x})$ and $\alpha(\vec{x},\vec{x}')$ are
          $<1$: although this would be silly. (Why?)</li>
        </ul>
      </li>
    </ul>
  </section>

  <section>
    <h2>The MH algorithm</h2>

    The complete (yet simple!) MH algorithm is as follows:

    <blockquote>

      <ol class="spaced">
        <li>Set $\vec{x}$ to an arbitrary initial state.</li>
        <li>Sample $\vec{x}'$ from a proposal distribution $q(\vec{x'}|\vec{x})$</li>
        <li>Evaluate the acceptance probability $\alpha(\vec{x}',\vec{x})$</li>
        <li>Sample $u\sim\text{Unif}(0,1)$.</li>
        <li>If $u&lt;\alpha(\vec{x}',\vec{x})$ then set $\vec{x}'\leftarrow\vec{x}$.</li>
        <li>Log $\vec{x}$ to file.</li>
        <li>Go to 2 (until the heat death of the universe).</li>
      </ol>
    </blockquote>
    
  </section>

</section>
<section>
  <section class="center">
    <h1>MCMC in practice</h1>
  </section>

  <section>
    <h2>Implementation example</h2>

    <p>Suppose we want to sample from the following posterior for a single variable $x$:</p>

    <div id="targetDensity"> </div>

    <p>Use a simple proposal distribution:</p>
    $$q_w(x'|x) = \begin{cases}
    1/w & x-\frac{w}{2} &lt; x' &lt; x+\frac{w}{2}\\
    0 & \text{otherwise}
    \end{cases}$$
  </section>

  <section>
    <h2>Implementation example</h2>

    <div id="mcmcTrace" style="width:100%"> </div>
  </section>
  
  <section>
    <h2>Implementation example</h2>

    <div style="font-size:0.5em;text-align:left">$w=1$:</div>
    <div>
      <div style="display:inline-block;width:70%" id="mcmcTrace_w1"></div>
      <div style="display:inline-block;width:20%" id="mcmcDensity_w1"></div>
    </div>

    <div class="fragment">
    <div style="font-size:0.5em;text-align:left">$w=3$:</div>
    <div>
      <div style="display:inline-block;width:70%" id="mcmcTrace_w2"></div>
      <div style="display:inline-block;width:20%" id="mcmcDensity_w2"></div>
    </div>
    </div>

    <div class="fragment">
    <div style="font-size:0.5em;text-align:left">$w=5$:</div>
    <div>
      <div style="display:inline-block;width:70%" id="mcmcTrace_w3"></div>
      <div style="display:inline-block;width:20%" id="mcmcDensity_w3"></div>
    </div>
    </div>
    <script src="plot_mcmcExamples.js"> </script>
  </section>

  <section>
    <h2>How do we assess convergence?</h2>

    <p>The easiest approach is simply to run multiple independent
    chains, each initialized from a unique starting point.</p>

    <img style="float:right;width:45%" data-src="MCMC_convergence_testing.png">
    <div style="width:50%;">
    <ul>
      <li>Chains can be run in parallel.</li>
      <li>Resulting sample distributions can be compared using (for example) Q-Q plots.</li>
      <li>Once convergence is attained, combining the results of
        multiple chains is perfectly acceptable.</li>
      </ul>
    </div>
  </section>

  <section>
    <h2>How do we assess mixing?</h2>

   <p>The key to assessing mixing is the autocorrelation function of the chain states:</p>

    $$\widehat{ACF}(l) = \frac{\sum_i x_i x_{i-l}}{\left(\sum_i x_i\right)^2}$$

    <img style="width:100%" data-src="MCMC_acf.png">

  </section>

  <section>
    <h2>Assessing Mixing (continued)</h2>

    <p>The lag required for this function to decay to within the
      vicinity of 0 is the gap between effectively independent
      samples, $\tau$.</p>

    <p>If $N$ is the total number of MCMC samples, we then define
    $$N_{\text{eff}}=\frac{N}{\tau}$$
    to be the <b>effective sample size</b> (ESS).</p>

    <p>The ESS is a rough <i>estimate</i> of the number of actual
      samples a chain has generated.</p>

    <blockquote>You should really only
      consider the order of magnitude of the ESS.</blockquote>
  </section>

  <section>
    <h2>Multivariate target distributions</h2>

    <ul>
      <li>MCMC is usually applied to posteriors with large numbers of dimensions.</li>
      <li>This is precisely the regime in which MCMC shines.</li>
      <li>A typical phylogenetic analysis (as we'll see later) may contain many hundreds
        of distinct parameters.</li>
      <li>How do we develop algorithms to sample from posteriors over
      these parameter spaces?</li>
    </ul>
  </section>

  <section>
    <h2>Complex proposals</h2>

    <p>The usual approach is to decompose the proposal function $q(\vec{x}'|\vec{x})$ in terms of a large number of simpler proposals:
      $$q(\vec{x}'|\vec{x})=\sum_j w_j q_j(\vec{x}'|\vec{x})$$</p>

    <ul>
      <li>Individual proposal functions $q_j(\vec{x}'|\vec{x})$ are
      sometimes called "operators", and the $w_j$ are called
      "weights".</li>
      <li>Individual operators are often constructed to be reversible:
      i.e. maintain detailed balance.</li>
      <li>However, individual operators are usually incapable of
      producing an ergodic chain on their own. (I.e. they may not be
      capable of exploring the entire support of the posterior.)</li>
    </ul>

  </section>

  <section>
    <h2>Example</h2>

    <div>
    <div id="targetDensity2d" style="margin:auto;width:70%;margin-bottom:0"></div>
    </div>
    <script src="plot_2dExamples.js"></script>

    <p style="margin-top:0em">These proposal operators are sufficient for ergodicity:</p>
      $q_1(\vec{x'}|\vec{x})=\delta(x_2'-x_2)g(x_1'|x_1)$, 
      $q_2(\vec{x'}|\vec{x})=\delta(x_1'-x_1)g(x_2'|x_2)$
    <p>where $g(x'|x)$ is the PDF for $\text{Unif}(x-w/2,x+w/2)$</p>
  </section>

  <section>
    <h2>Example (continued)</h2>

    <div id="mcmcTrace2dFirstTry" style="margin:auto;width:80%"></div>
  </section>

  <section>
    <h2>Correlated variables</h2>

    <ul>
      <li>Chain is mixing slowly because of strong correlations between the two
        parameters.</li>
      <li>Solution is to update both parameters simultaneously.</li>
      <li>Anticipating correlations between parameters is a key skill in designing efficient MCMC algorithms.</li>
      <li>In the Bayesian context, this often requires careful examination of the likelihood: non-identifiability is a source of such correlations.</li>
    </ul>
    <p>Include a third proposal operator:</p>
      $$q_3(\vec{x}'|\vec{x}) = \frac{1}{v}\int_{-v/2}^{v/2}\delta(x_1'-(x_1+a))\delta(x_2'-(x_2+a))\mathrm{d}a$$

  </section>

  <section>
    <h2>Mixing improvement with new operator</h2>

    <div id="mcmcTrace2dBetter" style="margin:auto;width:80%"></div>
  </section>

  <section>
    <h2>Alternative approach: Hamiltonian Monte Carlo</h2>
  </section>

</section>



<section>
  <section class="center">
    <h1>Reversible Jump MCMC</h1>
  </section>

  <section>
    <h2>The Problem</h2>
  </section>

  <section>
    <h2>The Solution</h2>
  </section>

  <section>
    <h2>Confusion abounds?</h2>
  </section>
</section>


<section>
  <section class="center">
    <h1>Model Selection</h1>
  </section>

  <section>
    <h2>The Marginal Likelihood</h2>
  </section>

  <section>
    <h2>The Harmonic Mean Estimator</h2>
    </section>

  <section>
    <h2>Thermodynamic Integration</h2>
  </section>

  <section>
    <h2>Annealing-Melting Integration</h2>
  </section>

  <section>
    <h2>Model-switch Integration</h2>
  </section>
</section>


<!--

*** Introduction
    
1. Bayesian inference

2. The problem:
Trade-off: conceptual clarity vs mathematical difficulty

2. Deterministic numerical techniques: direct integration, variational Bayes

*** Basic algorithm

3. Monte carlo techniques
  - Importance sampling
  - ABC

4. The Gibbs Sampler

5. Metropolis-Hastings

6. Single-variable MH implementation example

7. Convergence and mixing

9. Multiple dimensions and complex proposals

10. Multiple-variable MH implementation example

11. Correlated variables and mixing issues

*** Reversible jump MCMC

The difficulty

The solution

Confusion abounds!

*** Model selection via thermodynamic integration

-->

<!-- Topics still to include:

PMMH

-->
